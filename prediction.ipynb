{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train (502, 798)\n",
      "x_valid (56, 798)\n",
      "x_test (240, 798)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/hvgs\"\n",
    "# f_list = os.listdir(data_path)\n",
    "f_list = ['TCGA-LUNG.csv']\n",
    "file = os.path.join(data_path, f_list[0])\n",
    "df = pd.read_csv(file)\n",
    "x = df.values[:, 3:]\n",
    "y = df.values[:, 1:3]\n",
    "seed = 42\n",
    "duration_max = df.duration.max()\n",
    "num_pred_points = 1000\n",
    "duration_reference = [\n",
    "    duration_max / num_pred_points * i for i in range(num_pred_points)\n",
    "]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, random_state=42, train_size=0.7\n",
    ")\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train, y_train, random_state=42, train_size=0.9\n",
    ")\n",
    "\n",
    "print(f\"x train {x_train.shape}\\nx_valid {x_valid.shape}\\nx_test {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_modifier(y):\n",
    "    y_expand_lab = []\n",
    "    y_mask = []\n",
    "    for i, _y in enumerate(y):\n",
    "        # y_surv.append(_y[1])\n",
    "        # if i==0:\n",
    "        y_expand_lab.append((np.array(duration_reference) >= _y[0]) * 1)\n",
    "        if _y[1] == 0:\n",
    "            y_mask.append(~(np.array(duration_reference) >= _y[0]) * 1)\n",
    "        else:\n",
    "            y_mask.append(np.ones_like(y_expand_lab[-1]))\n",
    "            # y_expand = np.concatenate([y_expand, (np.array(duration_reference)>=_y[0])*1], axis=0)\n",
    "    y_expand_lab = torch.tensor(np.array(y_expand_lab).astype(float))\n",
    "    y_mask = torch.tensor(np.array(y_mask).astype(int))\n",
    "    return y, y_expand_lab, y_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mask = label_modifier(y_train)\n",
    "y_valid_mask = label_modifier(y_valid)\n",
    "y_test_mask = label_modifier(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_process(Dataset):\n",
    "    def __init__(self, x, y, device=\"cpu\", x_mean=None, x_std=None) -> None:\n",
    "        super().__init__()\n",
    "        self.x = torch.tensor(x.astype(np.float32)).to(device)\n",
    "        self.y_orig = torch.tensor(y[0].astype(int)).to(device)\n",
    "        self.y = y[1].to(device)\n",
    "        self.y_mask = y[2].to(device)\n",
    "\n",
    "        if x_mean is None:\n",
    "            self.mean = self.x.mean(0)\n",
    "            self.std = self.x.std(0)\n",
    "            # self.x = (self.x - self.mean) / self.std\n",
    "        else:\n",
    "            self.mean = x_mean\n",
    "            self.std = x_std\n",
    "        \n",
    "        self.x = (self.x - self.mean) / self.std \n",
    "\n",
    "    def return_mean_std(self):\n",
    "        return self.mean, self.std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx], self.y_mask[idx], self.y_orig[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = data_process(x_train, y_train_mask)\n",
    "m, s = data_tr.return_mean_std()\n",
    "data_val = data_process(x_valid, y_valid_mask, x_mean=m, x_std=s)\n",
    "data_test = data_process(x_test, y_test_mask, x_mean=m, x_std=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(data_tr, batch_size=32, shuffle=True)\n",
    "dl_valid = DataLoader(data_val, batch_size=32)\n",
    "dl_test = DataLoader(data_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, inp_size, num_pred_tgt, hidden=[500, 800]):\n",
    "        super().__init__()\n",
    "        hidden = [inp_size] + hidden + [num_pred_tgt]\n",
    "        self.linears = nn.ModuleList(\n",
    "            [nn.Linear(hidden[i], hidden[i + 1]) for i in range(len(hidden) - 1)]\n",
    "        )\n",
    "        self.n_linears = len(self.linears)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_linears - 1):\n",
    "            x = self.linears[i](x)\n",
    "            x = F.relu(x)\n",
    "        x = self.linears[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model(x.shape[1], num_pred_points)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss tensor(69796.8132, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(756.4169, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(296.2377, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(220.0404, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(197.1286, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(187.0769, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(173.5326, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(154.9047, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(128.7431, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Test loss tensor(96.4690, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[360], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     loss \u001b[39m=\u001b[39m (loss_fn(logit,tr_batch[\u001b[39m1\u001b[39m]) \u001b[39m*\u001b[39m tr_batch[\u001b[39m2\u001b[39m])\u001b[39m.\u001b[39mmean()\n\u001b[1;32m      8\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m----> 9\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     10\u001b[0m     loss_tr\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(loss_tr/(i+1))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(10000):\n",
    "    loss_tr = 0\n",
    "    for i, tr_batch in enumerate(dl_train):\n",
    "        m.train()\n",
    "        optimizer.zero_grad()\n",
    "        logit = m(tr_batch[0])\n",
    "        loss = (loss_fn(logit,tr_batch[1]) * tr_batch[2]).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_tr+=loss\n",
    "    # print(loss_tr/(i+1))\n",
    "    loss_test = 0\n",
    "    for i, test_batch in enumerate(dl_test):\n",
    "        m.eval()\n",
    "        # optimizer.zero_grad()\n",
    "        logit = m(test_batch[0])\n",
    "        loss = (loss_fn(logit,test_batch[1]) * test_batch[2]).mean()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        loss_test+=loss\n",
    "    if ep%100==0:\n",
    "\n",
    "        print('Test loss', loss_test/(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, test_batch in enumerate(dl_test):\n",
    "        m.eval()\n",
    "        # optimizer.zero_grad()\n",
    "        logit = m(test_batch[0])\n",
    "        loss = (loss_fn(test_batch[1], logit) * test_batch[2]).mean()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        loss_test+=loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0847,  0.0524, -0.0235,  ...,  1.2860,  1.0850,  1.0637],\n",
       "        [ 0.1321,  0.8096, -0.1600,  ...,  5.9836,  4.5919,  5.5155],\n",
       "        [ 0.0285,  0.3777, -0.0197,  ...,  1.9953,  1.5820,  1.6747],\n",
       "        ...,\n",
       "        [-0.0859,  0.3522,  0.0733,  ...,  2.1921,  1.6024,  1.8083],\n",
       "        [ 0.0062,  0.2223, -0.0444,  ...,  1.3009,  1.1183,  1.1493],\n",
       "        [ 0.2643,  0.4888, -0.1983,  ...,  3.4846,  3.0441,  3.1446]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3017, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(loss * l[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, random_state=42, train_size=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[688, 0],\n",
       "       [628, 1],\n",
       "       [0, 0],\n",
       "       [3964, 0],\n",
       "       [98, 0],\n",
       "       [661, 0],\n",
       "       [314, 0],\n",
       "       [1161, 0],\n",
       "       [1138, 0],\n",
       "       [2030, 0],\n",
       "       [482, 0],\n",
       "       [456, 0],\n",
       "       [1970, 1],\n",
       "       [2615, 0],\n",
       "       [2830, 0],\n",
       "       [576, 0],\n",
       "       [2381, 0],\n",
       "       [439, 1],\n",
       "       [808, 0],\n",
       "       [1456, 0],\n",
       "       [1092, 0],\n",
       "       [533, 0],\n",
       "       [923, 0],\n",
       "       [1590, 0],\n",
       "       [356, 0],\n",
       "       [1045, 0],\n",
       "       [694, 1],\n",
       "       [996, 0],\n",
       "       [1359, 0],\n",
       "       [1927, 0],\n",
       "       [1061, 1],\n",
       "       [605, 1],\n",
       "       [896, 0],\n",
       "       [2586, 0],\n",
       "       [1605, 0],\n",
       "       [2515, 0],\n",
       "       [771, 0],\n",
       "       [1495, 0],\n",
       "       [1017, 0],\n",
       "       [22, 0],\n",
       "       [541, 0],\n",
       "       [813, 0],\n",
       "       [3102, 0],\n",
       "       [133, 0],\n",
       "       [660, 0],\n",
       "       [2408, 0],\n",
       "       [5723, 0],\n",
       "       [1020, 1],\n",
       "       [605, 0],\n",
       "       [505, 0],\n",
       "       [547, 0],\n",
       "       [881, 0],\n",
       "       [245, 1],\n",
       "       [922, 0],\n",
       "       [1373, 0],\n",
       "       [1104, 0],\n",
       "       [2169, 0],\n",
       "       [1129, 0],\n",
       "       [463, 0],\n",
       "       [0, 0],\n",
       "       [2579, 0],\n",
       "       [2057, 0],\n",
       "       [56, 0],\n",
       "       [4627, 0],\n",
       "       [1379, 0],\n",
       "       [4845, 0],\n",
       "       [1548, 0],\n",
       "       [2007, 0],\n",
       "       [2087, 0],\n",
       "       [1070, 0],\n",
       "       [407, 0],\n",
       "       [1013, 0],\n",
       "       [402, 0],\n",
       "       [1088, 1],\n",
       "       [42, 0],\n",
       "       [995, 1],\n",
       "       [1170, 0],\n",
       "       [3406, 0],\n",
       "       [2085, 0],\n",
       "       [224, 1],\n",
       "       [1126, 0],\n",
       "       [2619, 0],\n",
       "       [398, 0],\n",
       "       [637, 0],\n",
       "       [1073, 0],\n",
       "       [2036, 0],\n",
       "       [280, 0],\n",
       "       [1547, 0],\n",
       "       [2901, 0],\n",
       "       [1622, 0],\n",
       "       [610, 0],\n",
       "       [546, 0],\n",
       "       [1534, 0],\n",
       "       [352, 0],\n",
       "       [1096, 0],\n",
       "       [1105, 0],\n",
       "       [959, 0],\n",
       "       [1892, 0],\n",
       "       [1108, 0],\n",
       "       [510, 0],\n",
       "       [262, 1],\n",
       "       [298, 0],\n",
       "       [768, 0],\n",
       "       [537, 0],\n",
       "       [2085, 0],\n",
       "       [3156, 0],\n",
       "       [4573, 0],\n",
       "       [1552, 1],\n",
       "       [1247, 0],\n",
       "       [972, 0],\n",
       "       [1372, 0],\n",
       "       [499, 0],\n",
       "       [796, 0],\n",
       "       [600, 0],\n",
       "       [711, 1],\n",
       "       [1585, 0],\n",
       "       [1885, 0],\n",
       "       [938, 0],\n",
       "       [618, 0],\n",
       "       [3765, 0],\n",
       "       [0, 0],\n",
       "       [1230, 0],\n",
       "       [2694, 1],\n",
       "       [379, 0],\n",
       "       [2247, 0],\n",
       "       [1303, 0],\n",
       "       [2625, 0],\n",
       "       [2271, 0]], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 184)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 184)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sksurv.datasets import load_whas500\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_whas500()\n",
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afb</th>\n",
       "      <th>age</th>\n",
       "      <th>av3</th>\n",
       "      <th>bmi</th>\n",
       "      <th>chf</th>\n",
       "      <th>cvd</th>\n",
       "      <th>diasbp</th>\n",
       "      <th>gender</th>\n",
       "      <th>hr</th>\n",
       "      <th>los</th>\n",
       "      <th>miord</th>\n",
       "      <th>mitype</th>\n",
       "      <th>sho</th>\n",
       "      <th>sysbp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.54051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.02398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.14290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.63187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.41255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.96454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.26862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.13576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.40905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.48575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     afb   age  av3       bmi  chf  cvd  diasbp  gender     hr   los  miord  \\\n",
       "0    1.0  83.0  0.0  25.54051  0.0  1.0    78.0     0.0   89.0   5.0    1.0   \n",
       "1    0.0  49.0  0.0  24.02398  0.0  1.0    60.0     0.0   84.0   5.0    0.0   \n",
       "2    0.0  70.0  0.0  22.14290  0.0  0.0    88.0     1.0   83.0   5.0    0.0   \n",
       "3    0.0  70.0  0.0  26.63187  1.0  1.0    76.0     0.0   65.0  10.0    0.0   \n",
       "4    0.0  70.0  0.0  24.41255  0.0  1.0    85.0     0.0   63.0   6.0    0.0   \n",
       "..   ...   ...  ...       ...  ...  ...     ...     ...    ...   ...    ...   \n",
       "495  1.0  76.0  0.0  27.96454  0.0  1.0    88.0     1.0   68.0   1.0    0.0   \n",
       "496  0.0  76.0  0.0  24.26862  0.0  1.0    96.0     1.0   88.0   3.0    0.0   \n",
       "497  1.0  57.0  0.0  42.13576  0.0  1.0    74.0     1.0  123.0   3.0    0.0   \n",
       "498  0.0  67.0  0.0  27.40905  0.0  1.0    62.0     0.0   59.0   1.0    0.0   \n",
       "499  0.0  98.0  0.0  19.48575  0.0  1.0   100.0     0.0   99.0   3.0    0.0   \n",
       "\n",
       "     mitype  sho  sysbp  \n",
       "0       0.0  0.0  152.0  \n",
       "1       1.0  0.0  120.0  \n",
       "2       1.0  0.0  147.0  \n",
       "3       1.0  0.0  123.0  \n",
       "4       1.0  0.0  135.0  \n",
       "..      ...  ...    ...  \n",
       "495     1.0  0.0  112.0  \n",
       "496     0.0  0.0  208.0  \n",
       "497     0.0  0.0  120.0  \n",
       "498     1.0  0.0  112.0  \n",
       "499     1.0  0.0  160.0  \n",
       "\n",
       "[500 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = CoxPHSurvivalAnalysis().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(False, 2.178e+03), (False, 2.172e+03), (False, 2.190e+03),\n",
       "       ( True, 2.970e+02), (False, 2.131e+03), ( True, 1.000e+00),\n",
       "       (False, 2.122e+03), ( True, 1.496e+03), ( True, 9.200e+02),\n",
       "       (False, 2.175e+03), (False, 2.173e+03), ( True, 1.671e+03),\n",
       "       (False, 2.192e+03), ( True, 8.650e+02), (False, 2.166e+03),\n",
       "       (False, 2.168e+03), ( True, 9.050e+02), ( True, 2.353e+03),\n",
       "       (False, 2.146e+03), ( True, 6.100e+01), ( True, 2.358e+03),\n",
       "       (False, 2.114e+03), (False, 2.132e+03), (False, 2.139e+03),\n",
       "       (False, 2.048e+03), (False, 2.152e+03), ( True, 6.000e+00),\n",
       "       (False, 2.156e+03), ( True, 1.180e+02), (False, 2.064e+03),\n",
       "       ( True, 8.490e+02), ( True, 7.140e+02), (False, 2.057e+03),\n",
       "       ( True, 2.000e+00), ( True, 7.000e+00), (False, 2.151e+03),\n",
       "       ( True, 6.000e+00), ( True, 4.220e+02), ( True, 3.540e+02),\n",
       "       (False, 2.065e+03), (False, 2.048e+03), ( True, 1.065e+03),\n",
       "       ( True, 5.350e+02), (False, 2.118e+03), ( True, 9.700e+01),\n",
       "       (False, 2.113e+03), ( True, 1.000e+02), (False, 2.032e+03),\n",
       "       ( True, 1.317e+03), (False, 2.126e+03), (False, 2.126e+03),\n",
       "       (False, 2.123e+03), ( True, 6.700e+02), ( True, 3.430e+02),\n",
       "       ( True, 3.000e+00), (False, 2.009e+03), ( True, 6.400e+01),\n",
       "       (False, 1.994e+03), ( True, 1.579e+03), (False, 1.993e+03),\n",
       "       ( True, 2.000e+00), (False, 1.955e+03), ( True, 4.200e+01),\n",
       "       (False, 1.964e+03), ( True, 1.548e+03), ( True, 4.460e+02),\n",
       "       (False, 1.976e+03), (False, 2.009e+03), (False, 1.942e+03),\n",
       "       ( True, 1.000e+00), ( True, 1.510e+02), (False, 2.006e+03),\n",
       "       (False, 2.086e+03), (False, 1.969e+03), (False, 1.939e+03),\n",
       "       (False, 1.939e+03), (False, 1.940e+03), ( True, 1.576e+03),\n",
       "       (False, 1.941e+03), ( True, 1.970e+02), (False, 1.933e+03),\n",
       "       ( True, 9.500e+01), ( True, 2.160e+03), (False, 2.084e+03),\n",
       "       (False, 2.145e+03), (False, 2.125e+03), (False, 1.920e+03),\n",
       "       ( True, 4.000e+00), ( True, 1.553e+03), ( True, 2.350e+02),\n",
       "       ( True, 1.920e+02), ( True, 1.233e+03), ( True, 8.800e+01),\n",
       "       ( True, 1.954e+03), ( True, 9.030e+02), ( True, 6.120e+02),\n",
       "       (False, 2.025e+03), ( True, 2.000e+00), ( True, 7.000e+00),\n",
       "       (False, 1.887e+03), ( True, 1.870e+02), ( True, 1.010e+02),\n",
       "       (False, 1.885e+03), ( True, 9.360e+02), ( True, 3.630e+02),\n",
       "       ( True, 1.048e+03), (False, 1.977e+03), (False, 1.936e+03),\n",
       "       (False, 1.887e+03), (False, 1.889e+03), (False, 1.923e+03),\n",
       "       (False, 2.123e+03), ( True, 1.100e+01), (False, 2.100e+03),\n",
       "       (False, 1.914e+03), (False, 1.883e+03), ( True, 3.300e+01),\n",
       "       (False, 1.931e+03), ( True, 1.506e+03), (False, 1.858e+03),\n",
       "       ( True, 6.000e+00), (False, 1.854e+03), (False, 1.847e+03),\n",
       "       (False, 1.858e+03), ( True, 1.870e+02), ( True, 4.600e+01),\n",
       "       (False, 2.061e+03), (False, 1.893e+03), (False, 2.108e+03),\n",
       "       ( True, 8.300e+01), ( True, 3.300e+01), ( True, 1.377e+03),\n",
       "       (False, 1.863e+03), (False, 1.880e+03), ( True, 1.359e+03),\n",
       "       (False, 1.831e+03), (False, 1.836e+03), ( True, 1.159e+03),\n",
       "       ( True, 1.130e+02), ( True, 1.217e+03), (False, 1.899e+03),\n",
       "       (False, 1.934e+03), ( True, 1.527e+03), (False, 1.954e+03),\n",
       "       (False, 1.979e+03), ( True, 1.232e+03), (False, 2.066e+03),\n",
       "       ( True, 1.624e+03), ( True, 5.300e+02), ( True, 1.096e+03),\n",
       "       ( True, 3.450e+02), (False, 1.919e+03), ( True, 1.577e+03),\n",
       "       (False, 1.883e+03), (False, 1.904e+03), (False, 2.083e+03),\n",
       "       ( True, 1.460e+02), ( True, 2.350e+03), ( True, 1.926e+03),\n",
       "       (False, 2.114e+03), ( True, 7.180e+02), (False, 1.451e+03),\n",
       "       ( True, 3.580e+02), ( True, 4.650e+02), (False, 1.381e+03),\n",
       "       ( True, 1.100e+01), (False, 1.385e+03), (False, 1.346e+03),\n",
       "       (False, 1.338e+03), ( True, 1.370e+02), (False, 1.449e+03),\n",
       "       ( True, 1.700e+01), ( True, 1.536e+03), ( True, 1.627e+03),\n",
       "       ( True, 1.000e+01), ( True, 1.000e+00), ( True, 1.000e+00),\n",
       "       ( True, 3.130e+02), ( True, 1.200e+03), (False, 1.384e+03),\n",
       "       ( True, 1.660e+02), (False, 1.420e+03), ( True, 5.620e+02),\n",
       "       (False, 1.302e+03), (False, 1.253e+03), (False, 1.438e+03),\n",
       "       (False, 1.400e+03), (False, 1.329e+03), (False, 1.325e+03),\n",
       "       (False, 1.257e+03), (False, 1.319e+03), (False, 1.256e+03),\n",
       "       (False, 1.298e+03), ( True, 1.800e+01), (False, 1.408e+03),\n",
       "       (False, 1.333e+03), (False, 1.378e+03), (False, 1.353e+03),\n",
       "       ( True, 6.540e+02), (False, 1.262e+03), (False, 1.314e+03),\n",
       "       (False, 1.280e+03), (False, 1.308e+03), (False, 1.433e+03),\n",
       "       (False, 1.430e+03), ( True, 7.000e+00), ( True, 1.000e+00),\n",
       "       (False, 1.272e+03), (False, 1.277e+03), ( True, 1.080e+02),\n",
       "       ( True, 2.000e+00), (False, 1.409e+03), (False, 1.454e+03),\n",
       "       ( True, 1.090e+02), (False, 1.363e+03), (False, 1.374e+03),\n",
       "       (False, 1.365e+03), ( True, 6.000e+00), ( True, 2.000e+02),\n",
       "       (False, 1.336e+03), (False, 1.317e+03), ( True, 1.340e+02),\n",
       "       ( True, 5.700e+01), ( True, 1.165e+03), ( True, 1.400e+02),\n",
       "       ( True, 2.000e+01), ( True, 7.000e+00), (False, 1.190e+03),\n",
       "       ( True, 1.400e+02), ( True, 1.054e+03), (False, 1.108e+03),\n",
       "       (False, 1.106e+03), (False, 1.106e+03), ( True, 2.590e+02),\n",
       "       ( True, 1.000e+00), (False, 1.125e+03), (False, 1.162e+03),\n",
       "       (False, 1.140e+03), (False, 1.157e+03), (False, 1.231e+03),\n",
       "       ( True, 9.530e+02), (False, 1.248e+03), (False, 1.235e+03),\n",
       "       (False, 1.290e+03), ( True, 1.152e+03), ( True, 1.900e+01),\n",
       "       (False, 1.251e+03), ( True, 1.136e+03), (False, 1.182e+03),\n",
       "       ( True, 2.000e+00), ( True, 1.690e+02), ( True, 7.040e+02),\n",
       "       ( True, 1.430e+02), ( True, 2.000e+00), (False, 1.232e+03),\n",
       "       ( True, 4.790e+02), (False, 1.211e+03), (False, 1.232e+03),\n",
       "       (False, 1.223e+03), (False, 1.191e+03), ( True, 1.100e+01),\n",
       "       ( True, 1.000e+01), (False, 1.117e+03), ( True, 1.174e+03),\n",
       "       (False, 1.123e+03), ( True, 3.850e+02), (False, 1.109e+03),\n",
       "       (False, 1.098e+03), (False, 1.114e+03), ( True, 6.400e+01),\n",
       "       (False, 1.151e+03), ( True, 9.100e+01), ( True, 6.140e+02),\n",
       "       (False, 1.140e+03), ( True, 5.420e+02), (False, 1.199e+03),\n",
       "       (False, 1.248e+03), (False, 1.163e+03), ( True, 3.210e+02),\n",
       "       (False, 1.187e+03), (False, 1.207e+03), ( True, 2.950e+02),\n",
       "       (False, 1.273e+03), (False, 1.189e+03), (False, 1.234e+03),\n",
       "       ( True, 5.200e+01), (False, 1.203e+03), ( True, 1.290e+02),\n",
       "       ( True, 2.970e+02), (False, 1.458e+03), ( True, 1.170e+02),\n",
       "       ( True, 3.120e+02), (False, 1.244e+03), (False, 1.160e+03),\n",
       "       ( True, 2.870e+02), ( True, 1.377e+03), (False, 1.320e+03),\n",
       "       (False, 1.245e+03), ( True, 4.970e+02), ( True, 2.890e+02),\n",
       "       (False, 1.150e+03), (False, 1.266e+03), (False, 1.266e+03),\n",
       "       (False, 1.265e+03), (False, 1.126e+03), ( True, 2.600e+01),\n",
       "       ( True, 1.320e+02), ( True, 5.520e+02), (False, 1.444e+03),\n",
       "       ( True, 1.400e+01), (False, 1.454e+03), (False, 1.123e+03),\n",
       "       (False, 1.279e+03), (False, 1.366e+03), (False, 1.196e+03),\n",
       "       ( True, 1.350e+02), (False, 1.114e+03), ( True, 3.700e+01),\n",
       "       (False, 1.390e+03), ( True, 3.200e+01), (False, 1.187e+03),\n",
       "       (False, 1.224e+03), (False, 1.121e+03), ( True, 1.900e+01),\n",
       "       (False, 1.456e+03), (False, 1.332e+03), (False, 1.174e+03),\n",
       "       (False, 1.274e+03), ( True, 3.820e+02), (False, 1.295e+03),\n",
       "       (False, 1.102e+03), (False, 1.169e+03), (False, 1.136e+03),\n",
       "       (False, 1.105e+03), (False, 1.320e+03), ( True, 1.279e+03),\n",
       "       (False, 1.178e+03), (False, 1.170e+03), (False, 1.336e+03),\n",
       "       ( True, 2.200e+01), (False, 1.103e+03), (False, 1.107e+03),\n",
       "       (False, 1.347e+03), ( True, 6.320e+02), (False, 1.161e+03),\n",
       "       (False, 1.388e+03), ( True, 6.000e+00), ( True, 3.200e+01),\n",
       "       (False, 5.730e+02), (False, 5.500e+02), (False, 5.700e+02),\n",
       "       ( True, 1.600e+01), ( True, 5.000e+00), (False, 5.780e+02),\n",
       "       ( True, 1.000e+00), (False, 5.500e+02), (False, 5.890e+02),\n",
       "       (False, 5.420e+02), ( True, 2.260e+02), ( True, 8.100e+01),\n",
       "       (False, 5.500e+02), (False, 5.290e+02), (False, 5.230e+02),\n",
       "       (False, 5.220e+02), (False, 5.100e+02), (False, 5.240e+02),\n",
       "       (False, 4.800e+02), (False, 4.590e+02), ( True, 4.190e+02),\n",
       "       (False, 4.330e+02), (False, 4.450e+02), (False, 5.160e+02),\n",
       "       ( True, 3.400e+01), (False, 4.120e+02), (False, 3.980e+02),\n",
       "       (False, 3.970e+02), (False, 4.030e+02), (False, 3.860e+02),\n",
       "       (False, 3.760e+02), (False, 3.730e+02), (False, 3.710e+02),\n",
       "       (False, 6.590e+02), ( True, 2.330e+02), (False, 6.310e+02),\n",
       "       ( True, 6.000e+01), ( True, 5.370e+02), ( True, 4.730e+02),\n",
       "       (False, 6.750e+02), ( True, 6.460e+02), (False, 5.890e+02),\n",
       "       (False, 6.060e+02), ( True, 2.740e+02), ( True, 1.690e+02),\n",
       "       (False, 5.680e+02), ( True, 6.730e+02), ( True, 5.590e+02),\n",
       "       ( True, 9.300e+01), ( True, 5.500e+01), (False, 5.440e+02),\n",
       "       ( True, 6.490e+02), (False, 5.070e+02), (False, 5.210e+02),\n",
       "       ( True, 4.060e+02), (False, 5.870e+02), (False, 5.320e+02),\n",
       "       ( True, 5.300e+01), (False, 4.660e+02), (False, 4.420e+02),\n",
       "       ( True, 1.450e+02), ( True, 3.300e+01), (False, 4.510e+02),\n",
       "       (False, 4.970e+02), ( True, 1.700e+01), (False, 5.060e+02),\n",
       "       (False, 5.210e+02), ( True, 1.160e+02), ( True, 6.200e+01),\n",
       "       ( True, 2.690e+02), ( True, 1.100e+01), (False, 5.160e+02),\n",
       "       (False, 4.780e+02), ( True, 4.900e+01), (False, 4.860e+02),\n",
       "       ( True, 7.600e+01), ( True, 1.000e+00), (False, 5.110e+02),\n",
       "       (False, 4.580e+02), (False, 4.400e+02), (False, 4.520e+02),\n",
       "       ( True, 1.800e+01), ( True, 1.800e+01), ( True, 5.000e+00),\n",
       "       ( True, 2.000e+01), ( True, 3.920e+02), ( True, 6.900e+01),\n",
       "       ( True, 2.000e+00), ( True, 2.200e+01), (False, 4.260e+02),\n",
       "       (False, 4.490e+02), ( True, 7.000e+00), (False, 4.030e+02),\n",
       "       (False, 3.710e+02), (False, 3.680e+02), (False, 4.110e+02),\n",
       "       (False, 3.900e+02), ( True, 3.590e+02), (False, 4.080e+02),\n",
       "       (False, 4.070e+02), (False, 4.220e+02), (False, 3.760e+02),\n",
       "       ( True, 3.590e+02), ( True, 5.700e+01), ( True, 3.280e+02),\n",
       "       (False, 4.120e+02), ( True, 3.000e+00), (False, 4.580e+02),\n",
       "       (False, 4.180e+02), (False, 4.450e+02), (False, 4.590e+02),\n",
       "       ( True, 2.000e+00), (False, 4.240e+02), (False, 4.160e+02),\n",
       "       ( True, 3.000e+00), (False, 4.270e+02), (False, 4.450e+02),\n",
       "       (False, 4.210e+02), ( True, 4.000e+00), (False, 3.990e+02),\n",
       "       (False, 5.190e+02), (False, 6.090e+02), (False, 4.460e+02),\n",
       "       (False, 6.260e+02), (False, 4.450e+02), ( True, 1.900e+01),\n",
       "       (False, 4.500e+02), (False, 4.000e+02), (False, 4.580e+02),\n",
       "       (False, 5.350e+02), ( True, 4.420e+02), ( True, 4.050e+02),\n",
       "       (False, 4.570e+02), (False, 4.370e+02), (False, 5.510e+02),\n",
       "       (False, 3.710e+02), ( True, 4.670e+02), ( True, 6.440e+02),\n",
       "       (False, 3.860e+02), (False, 5.540e+02), (False, 5.730e+02),\n",
       "       (False, 4.750e+02), ( True, 3.970e+02), ( True, 1.400e+01),\n",
       "       ( True, 7.000e+00), ( True, 6.900e+01), ( True, 3.100e+01),\n",
       "       ( True, 1.000e+01), (False, 6.620e+02), (False, 7.250e+02),\n",
       "       (False, 5.320e+02), ( True, 2.590e+02)],\n",
       "      dtype=[('fstat', '?'), ('lenfol', '<f8')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(False, 2.178e+03), (False, 2.172e+03), (False, 2.190e+03),\n",
       "       ( True, 2.970e+02), (False, 2.131e+03), ( True, 1.000e+00),\n",
       "       (False, 2.122e+03), ( True, 1.496e+03), ( True, 9.200e+02),\n",
       "       (False, 2.175e+03)], dtype=[('fstat', '?'), ('lenfol', '<f8')])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12595419847328243"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[3][1] / 2358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2358.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.07586148, 1.29704053, 1.82027862, 2.43809602, 1.71853033,\n",
       "       2.8242479 , 0.21493367, 1.12557932, 3.04750438, 1.433097  ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict(X.iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chf_funcs = estimator.predict_cumulative_hazard_function(X.iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = []\n",
    "for v in chf_funcs[0].x:\n",
    "    pred_x.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = []\n",
    "for _, v in y:\n",
    "    pred_y.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 14.0,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 22.0,\n",
       " 26.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 37.0,\n",
       " 42.0,\n",
       " 46.0,\n",
       " 49.0,\n",
       " 52.0,\n",
       " 53.0,\n",
       " 55.0,\n",
       " 57.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 62.0,\n",
       " 64.0,\n",
       " 69.0,\n",
       " 76.0,\n",
       " 81.0,\n",
       " 83.0,\n",
       " 88.0,\n",
       " 91.0,\n",
       " 93.0,\n",
       " 95.0,\n",
       " 97.0,\n",
       " 100.0,\n",
       " 101.0,\n",
       " 108.0,\n",
       " 109.0,\n",
       " 113.0,\n",
       " 116.0,\n",
       " 117.0,\n",
       " 118.0,\n",
       " 129.0,\n",
       " 132.0,\n",
       " 134.0,\n",
       " 135.0,\n",
       " 137.0,\n",
       " 140.0,\n",
       " 143.0,\n",
       " 145.0,\n",
       " 146.0,\n",
       " 151.0,\n",
       " 166.0,\n",
       " 169.0,\n",
       " 187.0,\n",
       " 192.0,\n",
       " 197.0,\n",
       " 200.0,\n",
       " 226.0,\n",
       " 233.0,\n",
       " 235.0,\n",
       " 259.0,\n",
       " 269.0,\n",
       " 274.0,\n",
       " 287.0,\n",
       " 289.0,\n",
       " 295.0,\n",
       " 297.0,\n",
       " 312.0,\n",
       " 313.0,\n",
       " 321.0,\n",
       " 328.0,\n",
       " 343.0,\n",
       " 345.0,\n",
       " 354.0,\n",
       " 358.0,\n",
       " 359.0,\n",
       " 363.0,\n",
       " 368.0,\n",
       " 371.0,\n",
       " 373.0,\n",
       " 376.0,\n",
       " 382.0,\n",
       " 385.0,\n",
       " 386.0,\n",
       " 390.0,\n",
       " 392.0,\n",
       " 397.0,\n",
       " 398.0,\n",
       " 399.0,\n",
       " 400.0,\n",
       " 403.0,\n",
       " 405.0,\n",
       " 406.0,\n",
       " 407.0,\n",
       " 408.0,\n",
       " 411.0,\n",
       " 412.0,\n",
       " 416.0,\n",
       " 418.0,\n",
       " 419.0,\n",
       " 421.0,\n",
       " 422.0,\n",
       " 424.0,\n",
       " 426.0,\n",
       " 427.0,\n",
       " 433.0,\n",
       " 437.0,\n",
       " 440.0,\n",
       " 442.0,\n",
       " 445.0,\n",
       " 446.0,\n",
       " 449.0,\n",
       " 450.0,\n",
       " 451.0,\n",
       " 452.0,\n",
       " 457.0,\n",
       " 458.0,\n",
       " 459.0,\n",
       " 465.0,\n",
       " 466.0,\n",
       " 467.0,\n",
       " 473.0,\n",
       " 475.0,\n",
       " 478.0,\n",
       " 479.0,\n",
       " 480.0,\n",
       " 486.0,\n",
       " 497.0,\n",
       " 506.0,\n",
       " 507.0,\n",
       " 510.0,\n",
       " 511.0,\n",
       " 516.0,\n",
       " 519.0,\n",
       " 521.0,\n",
       " 522.0,\n",
       " 523.0,\n",
       " 524.0,\n",
       " 529.0,\n",
       " 530.0,\n",
       " 532.0,\n",
       " 535.0,\n",
       " 537.0,\n",
       " 542.0,\n",
       " 544.0,\n",
       " 550.0,\n",
       " 551.0,\n",
       " 552.0,\n",
       " 554.0,\n",
       " 559.0,\n",
       " 562.0,\n",
       " 568.0,\n",
       " 570.0,\n",
       " 573.0,\n",
       " 578.0,\n",
       " 587.0,\n",
       " 589.0,\n",
       " 606.0,\n",
       " 609.0,\n",
       " 612.0,\n",
       " 614.0,\n",
       " 626.0,\n",
       " 631.0,\n",
       " 632.0,\n",
       " 644.0,\n",
       " 646.0,\n",
       " 649.0,\n",
       " 654.0,\n",
       " 659.0,\n",
       " 662.0,\n",
       " 670.0,\n",
       " 673.0,\n",
       " 675.0,\n",
       " 704.0,\n",
       " 714.0,\n",
       " 718.0,\n",
       " 725.0,\n",
       " 849.0,\n",
       " 865.0,\n",
       " 903.0,\n",
       " 905.0,\n",
       " 920.0,\n",
       " 936.0,\n",
       " 953.0,\n",
       " 1048.0,\n",
       " 1054.0,\n",
       " 1065.0,\n",
       " 1096.0,\n",
       " 1098.0,\n",
       " 1102.0,\n",
       " 1103.0,\n",
       " 1105.0,\n",
       " 1106.0,\n",
       " 1107.0,\n",
       " 1108.0,\n",
       " 1109.0,\n",
       " 1114.0,\n",
       " 1117.0,\n",
       " 1121.0,\n",
       " 1123.0,\n",
       " 1125.0,\n",
       " 1126.0,\n",
       " 1136.0,\n",
       " 1140.0,\n",
       " 1150.0,\n",
       " 1151.0,\n",
       " 1152.0,\n",
       " 1157.0,\n",
       " 1159.0,\n",
       " 1160.0,\n",
       " 1161.0,\n",
       " 1162.0,\n",
       " 1163.0,\n",
       " 1165.0,\n",
       " 1169.0,\n",
       " 1170.0,\n",
       " 1174.0,\n",
       " 1178.0,\n",
       " 1182.0,\n",
       " 1187.0,\n",
       " 1189.0,\n",
       " 1190.0,\n",
       " 1191.0,\n",
       " 1196.0,\n",
       " 1199.0,\n",
       " 1200.0,\n",
       " 1203.0,\n",
       " 1207.0,\n",
       " 1211.0,\n",
       " 1217.0,\n",
       " 1223.0,\n",
       " 1224.0,\n",
       " 1231.0,\n",
       " 1232.0,\n",
       " 1233.0,\n",
       " 1234.0,\n",
       " 1235.0,\n",
       " 1244.0,\n",
       " 1245.0,\n",
       " 1248.0,\n",
       " 1251.0,\n",
       " 1253.0,\n",
       " 1256.0,\n",
       " 1257.0,\n",
       " 1262.0,\n",
       " 1265.0,\n",
       " 1266.0,\n",
       " 1272.0,\n",
       " 1273.0,\n",
       " 1274.0,\n",
       " 1277.0,\n",
       " 1279.0,\n",
       " 1280.0,\n",
       " 1290.0,\n",
       " 1295.0,\n",
       " 1298.0,\n",
       " 1302.0,\n",
       " 1308.0,\n",
       " 1314.0,\n",
       " 1317.0,\n",
       " 1319.0,\n",
       " 1320.0,\n",
       " 1325.0,\n",
       " 1329.0,\n",
       " 1332.0,\n",
       " 1333.0,\n",
       " 1336.0,\n",
       " 1338.0,\n",
       " 1346.0,\n",
       " 1347.0,\n",
       " 1353.0,\n",
       " 1359.0,\n",
       " 1363.0,\n",
       " 1365.0,\n",
       " 1366.0,\n",
       " 1374.0,\n",
       " 1377.0,\n",
       " 1378.0,\n",
       " 1381.0,\n",
       " 1384.0,\n",
       " 1385.0,\n",
       " 1388.0,\n",
       " 1390.0,\n",
       " 1400.0,\n",
       " 1408.0,\n",
       " 1409.0,\n",
       " 1420.0,\n",
       " 1430.0,\n",
       " 1433.0,\n",
       " 1438.0,\n",
       " 1444.0,\n",
       " 1449.0,\n",
       " 1451.0,\n",
       " 1454.0,\n",
       " 1456.0,\n",
       " 1458.0,\n",
       " 1496.0,\n",
       " 1506.0,\n",
       " 1527.0,\n",
       " 1536.0,\n",
       " 1548.0,\n",
       " 1553.0,\n",
       " 1576.0,\n",
       " 1577.0,\n",
       " 1579.0,\n",
       " 1624.0,\n",
       " 1627.0,\n",
       " 1671.0,\n",
       " 1831.0,\n",
       " 1836.0,\n",
       " 1847.0,\n",
       " 1854.0,\n",
       " 1858.0,\n",
       " 1863.0,\n",
       " 1880.0,\n",
       " 1883.0,\n",
       " 1885.0,\n",
       " 1887.0,\n",
       " 1889.0,\n",
       " 1893.0,\n",
       " 1899.0,\n",
       " 1904.0,\n",
       " 1914.0,\n",
       " 1919.0,\n",
       " 1920.0,\n",
       " 1923.0,\n",
       " 1926.0,\n",
       " 1931.0,\n",
       " 1933.0,\n",
       " 1934.0,\n",
       " 1936.0,\n",
       " 1939.0,\n",
       " 1940.0,\n",
       " 1941.0,\n",
       " 1942.0,\n",
       " 1954.0,\n",
       " 1955.0,\n",
       " 1964.0,\n",
       " 1969.0,\n",
       " 1976.0,\n",
       " 1977.0,\n",
       " 1979.0,\n",
       " 1993.0,\n",
       " 1994.0,\n",
       " 2006.0,\n",
       " 2009.0,\n",
       " 2025.0,\n",
       " 2032.0,\n",
       " 2048.0,\n",
       " 2057.0,\n",
       " 2061.0,\n",
       " 2064.0,\n",
       " 2065.0,\n",
       " 2066.0,\n",
       " 2083.0,\n",
       " 2084.0,\n",
       " 2086.0,\n",
       " 2100.0,\n",
       " 2108.0,\n",
       " 2113.0,\n",
       " 2114.0,\n",
       " 2118.0,\n",
       " 2122.0,\n",
       " 2123.0,\n",
       " 2125.0,\n",
       " 2126.0,\n",
       " 2131.0,\n",
       " 2132.0,\n",
       " 2139.0,\n",
       " 2145.0,\n",
       " 2146.0,\n",
       " 2151.0,\n",
       " 2152.0,\n",
       " 2156.0,\n",
       " 2160.0,\n",
       " 2166.0,\n",
       " 2168.0,\n",
       " 2172.0,\n",
       " 2173.0,\n",
       " 2175.0,\n",
       " 2178.0,\n",
       " 2190.0,\n",
       " 2192.0,\n",
       " 2350.0,\n",
       " 2353.0,\n",
       " 2358.0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 14.0,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 22.0,\n",
       " 26.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 37.0,\n",
       " 42.0,\n",
       " 46.0,\n",
       " 49.0,\n",
       " 52.0,\n",
       " 53.0,\n",
       " 55.0,\n",
       " 57.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 62.0,\n",
       " 64.0,\n",
       " 69.0,\n",
       " 76.0,\n",
       " 81.0,\n",
       " 83.0,\n",
       " 88.0,\n",
       " 91.0,\n",
       " 93.0,\n",
       " 95.0,\n",
       " 97.0,\n",
       " 100.0,\n",
       " 101.0,\n",
       " 108.0,\n",
       " 109.0,\n",
       " 113.0,\n",
       " 116.0,\n",
       " 117.0,\n",
       " 118.0,\n",
       " 129.0,\n",
       " 132.0,\n",
       " 134.0,\n",
       " 135.0,\n",
       " 137.0,\n",
       " 140.0,\n",
       " 143.0,\n",
       " 145.0,\n",
       " 146.0,\n",
       " 151.0,\n",
       " 166.0,\n",
       " 169.0,\n",
       " 187.0,\n",
       " 192.0,\n",
       " 197.0,\n",
       " 200.0,\n",
       " 226.0,\n",
       " 233.0,\n",
       " 235.0,\n",
       " 259.0,\n",
       " 269.0,\n",
       " 274.0,\n",
       " 287.0,\n",
       " 289.0,\n",
       " 295.0,\n",
       " 297.0,\n",
       " 312.0,\n",
       " 313.0,\n",
       " 321.0,\n",
       " 328.0,\n",
       " 343.0,\n",
       " 345.0,\n",
       " 354.0,\n",
       " 358.0,\n",
       " 359.0,\n",
       " 363.0,\n",
       " 368.0,\n",
       " 371.0,\n",
       " 373.0,\n",
       " 376.0,\n",
       " 382.0,\n",
       " 385.0,\n",
       " 386.0,\n",
       " 390.0,\n",
       " 392.0,\n",
       " 397.0,\n",
       " 398.0,\n",
       " 399.0,\n",
       " 400.0,\n",
       " 403.0,\n",
       " 405.0,\n",
       " 406.0,\n",
       " 407.0,\n",
       " 408.0,\n",
       " 411.0,\n",
       " 412.0,\n",
       " 416.0,\n",
       " 418.0,\n",
       " 419.0,\n",
       " 421.0,\n",
       " 422.0,\n",
       " 424.0,\n",
       " 426.0,\n",
       " 427.0,\n",
       " 433.0,\n",
       " 437.0,\n",
       " 440.0,\n",
       " 442.0,\n",
       " 445.0,\n",
       " 446.0,\n",
       " 449.0,\n",
       " 450.0,\n",
       " 451.0,\n",
       " 452.0,\n",
       " 457.0,\n",
       " 458.0,\n",
       " 459.0,\n",
       " 465.0,\n",
       " 466.0,\n",
       " 467.0,\n",
       " 473.0,\n",
       " 475.0,\n",
       " 478.0,\n",
       " 479.0,\n",
       " 480.0,\n",
       " 486.0,\n",
       " 497.0,\n",
       " 506.0,\n",
       " 507.0,\n",
       " 510.0,\n",
       " 511.0,\n",
       " 516.0,\n",
       " 519.0,\n",
       " 521.0,\n",
       " 522.0,\n",
       " 523.0,\n",
       " 524.0,\n",
       " 529.0,\n",
       " 530.0,\n",
       " 532.0,\n",
       " 535.0,\n",
       " 537.0,\n",
       " 542.0,\n",
       " 544.0,\n",
       " 550.0,\n",
       " 551.0,\n",
       " 552.0,\n",
       " 554.0,\n",
       " 559.0,\n",
       " 562.0,\n",
       " 568.0,\n",
       " 570.0,\n",
       " 573.0,\n",
       " 578.0,\n",
       " 587.0,\n",
       " 589.0,\n",
       " 606.0,\n",
       " 609.0,\n",
       " 612.0,\n",
       " 614.0,\n",
       " 626.0,\n",
       " 631.0,\n",
       " 632.0,\n",
       " 644.0,\n",
       " 646.0,\n",
       " 649.0,\n",
       " 654.0,\n",
       " 659.0,\n",
       " 662.0,\n",
       " 670.0,\n",
       " 673.0,\n",
       " 675.0,\n",
       " 704.0,\n",
       " 714.0,\n",
       " 718.0,\n",
       " 725.0,\n",
       " 849.0,\n",
       " 865.0,\n",
       " 903.0,\n",
       " 905.0,\n",
       " 920.0,\n",
       " 936.0,\n",
       " 953.0,\n",
       " 1048.0,\n",
       " 1054.0,\n",
       " 1065.0,\n",
       " 1096.0,\n",
       " 1098.0,\n",
       " 1102.0,\n",
       " 1103.0,\n",
       " 1105.0,\n",
       " 1106.0,\n",
       " 1107.0,\n",
       " 1108.0,\n",
       " 1109.0,\n",
       " 1114.0,\n",
       " 1117.0,\n",
       " 1121.0,\n",
       " 1123.0,\n",
       " 1125.0,\n",
       " 1126.0,\n",
       " 1136.0,\n",
       " 1140.0,\n",
       " 1150.0,\n",
       " 1151.0,\n",
       " 1152.0,\n",
       " 1157.0,\n",
       " 1159.0,\n",
       " 1160.0,\n",
       " 1161.0,\n",
       " 1162.0,\n",
       " 1163.0,\n",
       " 1165.0,\n",
       " 1169.0,\n",
       " 1170.0,\n",
       " 1174.0,\n",
       " 1178.0,\n",
       " 1182.0,\n",
       " 1187.0,\n",
       " 1189.0,\n",
       " 1190.0,\n",
       " 1191.0,\n",
       " 1196.0,\n",
       " 1199.0,\n",
       " 1200.0,\n",
       " 1203.0,\n",
       " 1207.0,\n",
       " 1211.0,\n",
       " 1217.0,\n",
       " 1223.0,\n",
       " 1224.0,\n",
       " 1231.0,\n",
       " 1232.0,\n",
       " 1233.0,\n",
       " 1234.0,\n",
       " 1235.0,\n",
       " 1244.0,\n",
       " 1245.0,\n",
       " 1248.0,\n",
       " 1251.0,\n",
       " 1253.0,\n",
       " 1256.0,\n",
       " 1257.0,\n",
       " 1262.0,\n",
       " 1265.0,\n",
       " 1266.0,\n",
       " 1272.0,\n",
       " 1273.0,\n",
       " 1274.0,\n",
       " 1277.0,\n",
       " 1279.0,\n",
       " 1280.0,\n",
       " 1290.0,\n",
       " 1295.0,\n",
       " 1298.0,\n",
       " 1302.0,\n",
       " 1308.0,\n",
       " 1314.0,\n",
       " 1317.0,\n",
       " 1319.0,\n",
       " 1320.0,\n",
       " 1325.0,\n",
       " 1329.0,\n",
       " 1332.0,\n",
       " 1333.0,\n",
       " 1336.0,\n",
       " 1338.0,\n",
       " 1346.0,\n",
       " 1347.0,\n",
       " 1353.0,\n",
       " 1359.0,\n",
       " 1363.0,\n",
       " 1365.0,\n",
       " 1366.0,\n",
       " 1374.0,\n",
       " 1377.0,\n",
       " 1378.0,\n",
       " 1381.0,\n",
       " 1384.0,\n",
       " 1385.0,\n",
       " 1388.0,\n",
       " 1390.0,\n",
       " 1400.0,\n",
       " 1408.0,\n",
       " 1409.0,\n",
       " 1420.0,\n",
       " 1430.0,\n",
       " 1433.0,\n",
       " 1438.0,\n",
       " 1444.0,\n",
       " 1449.0,\n",
       " 1451.0,\n",
       " 1454.0,\n",
       " 1456.0,\n",
       " 1458.0,\n",
       " 1496.0,\n",
       " 1506.0,\n",
       " 1527.0,\n",
       " 1536.0,\n",
       " 1548.0,\n",
       " 1553.0,\n",
       " 1576.0,\n",
       " 1577.0,\n",
       " 1579.0,\n",
       " 1624.0,\n",
       " 1627.0,\n",
       " 1671.0,\n",
       " 1831.0,\n",
       " 1836.0,\n",
       " 1847.0,\n",
       " 1854.0,\n",
       " 1858.0,\n",
       " 1863.0,\n",
       " 1880.0,\n",
       " 1883.0,\n",
       " 1885.0,\n",
       " 1887.0,\n",
       " 1889.0,\n",
       " 1893.0,\n",
       " 1899.0,\n",
       " 1904.0,\n",
       " 1914.0,\n",
       " 1919.0,\n",
       " 1920.0,\n",
       " 1923.0,\n",
       " 1926.0,\n",
       " 1931.0,\n",
       " 1933.0,\n",
       " 1934.0,\n",
       " 1936.0,\n",
       " 1939.0,\n",
       " 1940.0,\n",
       " 1941.0,\n",
       " 1942.0,\n",
       " 1954.0,\n",
       " 1955.0,\n",
       " 1964.0,\n",
       " 1969.0,\n",
       " 1976.0,\n",
       " 1977.0,\n",
       " 1979.0,\n",
       " 1993.0,\n",
       " 1994.0,\n",
       " 2006.0,\n",
       " 2009.0,\n",
       " 2025.0,\n",
       " 2032.0,\n",
       " 2048.0,\n",
       " 2057.0,\n",
       " 2061.0,\n",
       " 2064.0,\n",
       " 2065.0,\n",
       " 2066.0,\n",
       " 2083.0,\n",
       " 2084.0,\n",
       " 2086.0,\n",
       " 2100.0,\n",
       " 2108.0,\n",
       " 2113.0,\n",
       " 2114.0,\n",
       " 2118.0,\n",
       " 2122.0,\n",
       " 2123.0,\n",
       " 2125.0,\n",
       " 2126.0,\n",
       " 2131.0,\n",
       " 2132.0,\n",
       " 2139.0,\n",
       " 2145.0,\n",
       " 2146.0,\n",
       " 2151.0,\n",
       " 2152.0,\n",
       " 2156.0,\n",
       " 2160.0,\n",
       " 2166.0,\n",
       " 2168.0,\n",
       " 2172.0,\n",
       " 2173.0,\n",
       " 2175.0,\n",
       " 2178.0,\n",
       " 2190.0,\n",
       " 2192.0,\n",
       " 2350.0,\n",
       " 2353.0,\n",
       " 2358.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sorted(pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fn in chf_funcs:\n",
    "    plt.step(fn.x, fn(fn.x), where=\"post\")\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StepFunction(x=array([1.000e+00, 2.000e+00, 3.000e+00, 4.000e+00, 5.000e+00, 6.000e+00,\n",
       "       7.000e+00, 1.000e+01, 1.100e+01, 1.400e+01, 1.600e+01, 1.700e+01,\n",
       "       1.800e+01, 1.900e+01, 2.000e+01, 2.200e+01, 2.600e+01, 3.100e+01,\n",
       "       3.200e+01, 3.300e+01, 3.400e+01, 3.700e+01, 4.200e+01, 4.600e+01,\n",
       "       4.900e+01, 5.200e+01, 5.300e+01, 5.500e+01, 5.700e+01, 6.000e+01,\n",
       "       6.100e+01, 6.200e+01, 6.400e+01, 6.900e+01, 7.600e+01, 8.100e+01,\n",
       "       8.300e+01, 8.800e+01, 9.100e+01, 9.300e+01, 9.500e+01, 9.700e+01,\n",
       "       1.000e+02, 1.010e+02, 1.080e+02, 1.090e+02, 1.130e+02, 1.160e+02,\n",
       "       1.170e+02, 1.180e+02, 1.290e+02, 1.320e+02, 1.340e+02, 1.350e+02,\n",
       "       1.370e+02, 1.400e+02, 1.430e+02, 1.450e+02, 1.460e+02, 1.510e+02,\n",
       "       1.660e+02, 1.690e+02, 1.870e+02, 1.920e+02, 1.970e+02, 2.000e+02,\n",
       "       2.260e+02, 2.330e+02, 2.350e+02, 2.590e+02, 2.690e+02, 2.740e+02,\n",
       "       2.870e+02, 2.890e+02, 2.950e+02, 2.970e+02, 3.120e+02, 3.130e+02,\n",
       "       3.210e+02, 3.280e+02, 3.430e+02, 3.450e+02, 3.540e+02, 3.580e+02,\n",
       "       3.590e+02, 3.630e+02, 3.680e+02, 3.710e+02, 3.730e+02, 3.760e+02,\n",
       "       3.820e+02, 3.850e+02, 3.860e+02, 3.900e+02, 3.920e+02, 3.970e+02,\n",
       "       3.980e+02, 3.990e+02, 4.000e+02, 4.030e+02, 4.050e+02, 4.060e+02,\n",
       "       4.070e+02, 4.080e+02, 4.110e+02, 4.120e+02, 4.160e+02, 4.180e+02,\n",
       "       4.190e+02, 4.210e+02, 4.220e+02, 4.240e+02, 4.260e+02, 4.270e+02,\n",
       "       4.330e+02, 4.370e+02, 4.400e+02, 4.420e+02, 4.450e+02, 4.460e+02,\n",
       "       4.490e+02, 4.500e+02, 4.510e+02, 4.520e+02, 4.570e+02, 4.580e+02,\n",
       "       4.590e+02, 4.650e+02, 4.660e+02, 4.670e+02, 4.730e+02, 4.750e+02,\n",
       "       4.780e+02, 4.790e+02, 4.800e+02, 4.860e+02, 4.970e+02, 5.060e+02,\n",
       "       5.070e+02, 5.100e+02, 5.110e+02, 5.160e+02, 5.190e+02, 5.210e+02,\n",
       "       5.220e+02, 5.230e+02, 5.240e+02, 5.290e+02, 5.300e+02, 5.320e+02,\n",
       "       5.350e+02, 5.370e+02, 5.420e+02, 5.440e+02, 5.500e+02, 5.510e+02,\n",
       "       5.520e+02, 5.540e+02, 5.590e+02, 5.620e+02, 5.680e+02, 5.700e+02,\n",
       "       5.730e+02, 5.780e+02, 5.870e+02, 5.890e+02, 6.060e+02, 6.090e+02,\n",
       "       6.120e+02, 6.140e+02, 6.260e+02, 6.310e+02, 6.320e+02, 6.440e+02,\n",
       "       6.460e+02, 6.490e+02, 6.540e+02, 6.590e+02, 6.620e+02, 6.700e+02,\n",
       "       6.730e+02, 6.750e+02, 7.040e+02, 7.140e+02, 7.180e+02, 7.250e+02,\n",
       "       8.490e+02, 8.650e+02, 9.030e+02, 9.050e+02, 9.200e+02, 9.360e+02,\n",
       "       9.530e+02, 1.048e+03, 1.054e+03, 1.065e+03, 1.096e+03, 1.098e+03,\n",
       "       1.102e+03, 1.103e+03, 1.105e+03, 1.106e+03, 1.107e+03, 1.108e+03,\n",
       "       1.109e+03, 1.114e+03, 1.117e+03, 1.121e+03, 1.123e+03, 1.125e+03,\n",
       "       1.126e+03, 1.136e+03, 1.140e+03, 1.150e+03, 1.151e+03, 1.152e+03,\n",
       "       1.157e+03, 1.159e+03, 1.160e+03, 1.161e+03, 1.162e+03, 1.163e+03,\n",
       "       1.165e+03, 1.169e+03, 1.170e+03, 1.174e+03, 1.178e+03, 1.182e+03,\n",
       "       1.187e+03, 1.189e+03, 1.190e+03, 1.191e+03, 1.196e+03, 1.199e+03,\n",
       "       1.200e+03, 1.203e+03, 1.207e+03, 1.211e+03, 1.217e+03, 1.223e+03,\n",
       "       1.224e+03, 1.231e+03, 1.232e+03, 1.233e+03, 1.234e+03, 1.235e+03,\n",
       "       1.244e+03, 1.245e+03, 1.248e+03, 1.251e+03, 1.253e+03, 1.256e+03,\n",
       "       1.257e+03, 1.262e+03, 1.265e+03, 1.266e+03, 1.272e+03, 1.273e+03,\n",
       "       1.274e+03, 1.277e+03, 1.279e+03, 1.280e+03, 1.290e+03, 1.295e+03,\n",
       "       1.298e+03, 1.302e+03, 1.308e+03, 1.314e+03, 1.317e+03, 1.319e+03,\n",
       "       1.320e+03, 1.325e+03, 1.329e+03, 1.332e+03, 1.333e+03, 1.336e+03,\n",
       "       1.338e+03, 1.346e+03, 1.347e+03, 1.353e+03, 1.359e+03, 1.363e+03,\n",
       "       1.365e+03, 1.366e+03, 1.374e+03, 1.377e+03, 1.378e+03, 1.381e+03,\n",
       "       1.384e+03, 1.385e+03, 1.388e+03, 1.390e+03, 1.400e+03, 1.408e+03,\n",
       "       1.409e+03, 1.420e+03, 1.430e+03, 1.433e+03, 1.438e+03, 1.444e+03,\n",
       "       1.449e+03, 1.451e+03, 1.454e+03, 1.456e+03, 1.458e+03, 1.496e+03,\n",
       "       1.506e+03, 1.527e+03, 1.536e+03, 1.548e+03, 1.553e+03, 1.576e+03,\n",
       "       1.577e+03, 1.579e+03, 1.624e+03, 1.627e+03, 1.671e+03, 1.831e+03,\n",
       "       1.836e+03, 1.847e+03, 1.854e+03, 1.858e+03, 1.863e+03, 1.880e+03,\n",
       "       1.883e+03, 1.885e+03, 1.887e+03, 1.889e+03, 1.893e+03, 1.899e+03,\n",
       "       1.904e+03, 1.914e+03, 1.919e+03, 1.920e+03, 1.923e+03, 1.926e+03,\n",
       "       1.931e+03, 1.933e+03, 1.934e+03, 1.936e+03, 1.939e+03, 1.940e+03,\n",
       "       1.941e+03, 1.942e+03, 1.954e+03, 1.955e+03, 1.964e+03, 1.969e+03,\n",
       "       1.976e+03, 1.977e+03, 1.979e+03, 1.993e+03, 1.994e+03, 2.006e+03,\n",
       "       2.009e+03, 2.025e+03, 2.032e+03, 2.048e+03, 2.057e+03, 2.061e+03,\n",
       "       2.064e+03, 2.065e+03, 2.066e+03, 2.083e+03, 2.084e+03, 2.086e+03,\n",
       "       2.100e+03, 2.108e+03, 2.113e+03, 2.114e+03, 2.118e+03, 2.122e+03,\n",
       "       2.123e+03, 2.125e+03, 2.126e+03, 2.131e+03, 2.132e+03, 2.139e+03,\n",
       "       2.145e+03, 2.146e+03, 2.151e+03, 2.152e+03, 2.156e+03, 2.160e+03,\n",
       "       2.166e+03, 2.168e+03, 2.172e+03, 2.173e+03, 2.175e+03, 2.178e+03,\n",
       "       2.190e+03, 2.192e+03, 2.350e+03, 2.353e+03, 2.358e+03]), y=array([0.00073404, 0.00148639, 0.00177977, 0.00198327, 0.00219078,\n",
       "       0.00271946, 0.00337609, 0.00372451, 0.00420039, 0.00444076,\n",
       "       0.00456537, 0.00481624, 0.00519384, 0.00557306, 0.00583117,\n",
       "       0.00609495, 0.00622921, 0.00636412, 0.00663533, 0.00704496,\n",
       "       0.00718297, 0.00732213, 0.00746203, 0.0076021 , 0.00774233,\n",
       "       0.00788411, 0.00802796, 0.00817225, 0.00846161, 0.00860819,\n",
       "       0.00875541, 0.00890296, 0.00919931, 0.00949835, 0.00964864,\n",
       "       0.00979925, 0.00995019, 0.01010162, 0.01025392, 0.01040684,\n",
       "       0.01056032, 0.01071399, 0.01086812, 0.01102295, 0.01117878,\n",
       "       0.01133594, 0.01149509, 0.01165443, 0.01181383, 0.01197357,\n",
       "       0.0121343 , 0.01229646, 0.01245887, 0.01262281, 0.01278753,\n",
       "       0.01311817, 0.0132857 , 0.01345484, 0.01362403, 0.0137937 ,\n",
       "       0.01396438, 0.01430976, 0.0146655 , 0.0148449 , 0.01502481,\n",
       "       0.01520569, 0.01538886, 0.01557306, 0.01575754, 0.01612785,\n",
       "       0.0163146 , 0.01650186, 0.01668931, 0.01687883, 0.01706881,\n",
       "       0.01745606, 0.01765037, 0.01784789, 0.01804836, 0.01824935,\n",
       "       0.01845133, 0.01865575, 0.01886145, 0.01906897, 0.01948648,\n",
       "       0.01969779, 0.01969779, 0.01969779, 0.01969779, 0.01969779,\n",
       "       0.01991456, 0.02013244, 0.02013244, 0.02013244, 0.0203528 ,\n",
       "       0.0205735 , 0.0205735 , 0.0205735 , 0.0205735 , 0.0205735 ,\n",
       "       0.02079831, 0.02102335, 0.02102335, 0.02102335, 0.02102335,\n",
       "       0.02102335, 0.02102335, 0.02102335, 0.02125379, 0.02125379,\n",
       "       0.02149307, 0.02149307, 0.02149307, 0.02149307, 0.02149307,\n",
       "       0.02149307, 0.02149307, 0.02173545, 0.02173545, 0.02198248,\n",
       "       0.02198248, 0.02198248, 0.02198248, 0.02198248, 0.02198248,\n",
       "       0.02198248, 0.02198248, 0.02224133, 0.02224133, 0.02250207,\n",
       "       0.02276364, 0.02276364, 0.02276364, 0.0230269 , 0.0230269 ,\n",
       "       0.0230269 , 0.02329061, 0.02329061, 0.02329061, 0.02329061,\n",
       "       0.02329061, 0.02329061, 0.02329061, 0.02329061, 0.02329061,\n",
       "       0.02329061, 0.02329061, 0.02329061, 0.02357413, 0.02357413,\n",
       "       0.02386038, 0.02415505, 0.02445086, 0.02445086, 0.02445086,\n",
       "       0.02445086, 0.02475522, 0.02475522, 0.02506459, 0.02537555,\n",
       "       0.02537555, 0.02537555, 0.02537555, 0.02537555, 0.02537555,\n",
       "       0.02537555, 0.02537555, 0.02537555, 0.02570427, 0.02603472,\n",
       "       0.02603472, 0.02603472, 0.02637275, 0.02671504, 0.02705957,\n",
       "       0.02742003, 0.02778247, 0.02778247, 0.02778247, 0.02815837,\n",
       "       0.02853721, 0.02853721, 0.02891979, 0.02930482, 0.0296919 ,\n",
       "       0.0296919 , 0.03008537, 0.03048735, 0.03089135, 0.03129806,\n",
       "       0.03170908, 0.03212369, 0.03254182, 0.03296603, 0.03339066,\n",
       "       0.0338221 , 0.03425608, 0.03425608, 0.03425608, 0.03425608,\n",
       "       0.03425608, 0.03425608, 0.03425608, 0.03425608, 0.03425608,\n",
       "       0.03425608, 0.03425608, 0.03425608, 0.03425608, 0.03425608,\n",
       "       0.03425608, 0.03471212, 0.03471212, 0.03471212, 0.03471212,\n",
       "       0.03518111, 0.03518111, 0.03567519, 0.03567519, 0.03567519,\n",
       "       0.03567519, 0.03567519, 0.0361788 , 0.0361788 , 0.0361788 ,\n",
       "       0.0367003 , 0.0367003 , 0.0367003 , 0.0367003 , 0.0367003 ,\n",
       "       0.0367003 , 0.0367003 , 0.0367003 , 0.0367003 , 0.03725075,\n",
       "       0.03725075, 0.03725075, 0.03725075, 0.03780595, 0.03780595,\n",
       "       0.03780595, 0.03780595, 0.03837793, 0.03895996, 0.03895996,\n",
       "       0.03895996, 0.03895996, 0.03895996, 0.03895996, 0.03895996,\n",
       "       0.03895996, 0.03895996, 0.03895996, 0.03895996, 0.03895996,\n",
       "       0.03895996, 0.03895996, 0.03895996, 0.03895996, 0.03895996,\n",
       "       0.03960607, 0.03960607, 0.03960607, 0.03960607, 0.03960607,\n",
       "       0.03960607, 0.03960607, 0.03960607, 0.04028717, 0.04028717,\n",
       "       0.04028717, 0.04028717, 0.04028717, 0.04028717, 0.04028717,\n",
       "       0.04028717, 0.04028717, 0.04028717, 0.04028717, 0.04028717,\n",
       "       0.04103439, 0.04103439, 0.04103439, 0.04103439, 0.04103439,\n",
       "       0.04267178, 0.04267178, 0.04267178, 0.04267178, 0.04267178,\n",
       "       0.04267178, 0.04267178, 0.04267178, 0.04267178, 0.04267178,\n",
       "       0.04267178, 0.04267178, 0.04267178, 0.04267178, 0.04267178,\n",
       "       0.04267178, 0.04267178, 0.04267178, 0.04267178, 0.04267178,\n",
       "       0.04360339, 0.04453767, 0.04548241, 0.04643425, 0.0474057 ,\n",
       "       0.04839852, 0.04945487, 0.05051724, 0.05158049, 0.05268482,\n",
       "       0.05380331, 0.05493137, 0.05493137, 0.05493137, 0.05493137,\n",
       "       0.05493137, 0.05493137, 0.05493137, 0.05493137, 0.05493137,\n",
       "       0.05493137, 0.05493137, 0.05493137, 0.05493137, 0.05493137,\n",
       "       0.05493137, 0.05493137, 0.05493137, 0.05493137, 0.05493137,\n",
       "       0.05642004, 0.05642004, 0.05642004, 0.05642004, 0.05642004,\n",
       "       0.05642004, 0.05642004, 0.05642004, 0.05642004, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.05817712, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.05817712, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.05817712, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.05817712, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.05817712, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.05817712, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.05817712, 0.05817712,\n",
       "       0.05817712, 0.05817712, 0.05817712, 0.06701862, 0.06701862,\n",
       "       0.06701862, 0.06701862, 0.06701862, 0.06701862, 0.06701862,\n",
       "       0.06701862, 0.06701862, 0.09192455, 0.23086726, 0.62476188]), a=3.6584535413134884, b=0.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chf_funcs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
